{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json \n",
    "import time \n",
    "import csv\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_writer(filename,to_write):\n",
    "    headers = to_write.keys()\n",
    "    file_exists = os.path.isfile(filename)\n",
    "\n",
    "    with open(filename,'a') as f:\n",
    "        writer = csv.DictWriter(f, delimiter=',',fieldnames=headers)\n",
    "        \n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "\n",
    "        writer.writerow(to_write)\n",
    "def execute_req(url, headers=None,params=None): \n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    \n",
    "    return json.loads(response.text)\n",
    "\n",
    "def parse_tweets(jdata): \n",
    "    for tweet in jdata['data']: \n",
    "        yield tweet\n",
    "\n",
    "        \n",
    "def user_merger(tweets,users): \n",
    "    out = []\n",
    "    for tweet in tweets:\n",
    "        for user in users: \n",
    "            if tweet['author_id'] == user['id']:\n",
    "                tweet['user_scr_name'] = user['username']\n",
    "                tweet['username'] = user['name']\n",
    "                out.append(tweet)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def id_search(id_string, dic_list):\n",
    "    for e in dic_list :\n",
    "        if e['id'] == id_string:\n",
    "            return e\n",
    "\n",
    "\n",
    "def rt_merger(tweets,extended): \n",
    "    out =[]\n",
    "    for tweet in tweets:\n",
    "        tweet['retweeted_status']=''\n",
    "        if 'referenced_tweets' in tweet and tweet['referenced_tweets'][0]['type']=='retweeted': \n",
    "            id_s = tweet['referenced_tweets'][0]['id']\n",
    "   \n",
    "            out_r = id_search(id_s,extended)\n",
    "            tweet['retweeted_status'] = out_r['text']\n",
    "            tweet['retweet_count'] = out_r['public_metrics']['retweet_count'] \n",
    "            tweet['favorite_count'] = out_r['public_metrics']['like_count']\n",
    "            tweet['comm_count'] = out_r['public_metrics']['quote_count'] \n",
    "\n",
    "        out.append(tweet)\n",
    "            \n",
    "       \n",
    "    return out\n",
    "\n",
    "\n",
    "def rt_user_merger(tweets, auts):\n",
    "    for tweet in tweets:\n",
    "        if tweet['text'].startswith('RT'):\n",
    "            try: \n",
    "             rt_user = re.findall('(?<=RT\\s)@\\S+', tweet['text'])[0]\n",
    "             rt_user = rt_user.strip('@')\n",
    "             rt_user = rt_user.strip(':')\n",
    "\n",
    "             for a in auts:\n",
    "                if a['username'] ==rt_user:\n",
    "       \n",
    "                    tweet['rt_user'] = rt_user\n",
    "                    tweet['rt_followers'] = a['public_metrics']['followers_count']\n",
    "                    break\n",
    "            except: \n",
    "             pass\n",
    "\n",
    "    return tweets\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def assemble_tweet(tweet_d):\n",
    "    out={}\n",
    "    fields_e = fields_l + ['user_scr_name','username','retweeted_status','rt_followers', 'retweet_count','comm_count','favorite_count']\n",
    "    \n",
    "    for f in fields_e:\n",
    "        if f in tweet_d: \n",
    "            out[f] = tweet_d[f]\n",
    "        else: \n",
    "            out[f] = ''\n",
    "            \n",
    "\n",
    "    \n",
    "    try:\n",
    "        out['exp_url'] = tweet_d['entities']['urls'][0]['expanded_url']\n",
    "    except:\n",
    "        out['exp_url']='n/a'\n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    return out\n",
    "\n",
    "def process_tweets(j_response): \n",
    "\n",
    "        \n",
    "\n",
    "        tweets=j_response['data']\n",
    "    \n",
    "\n",
    "        users = j_response['includes']['users']\n",
    "        extended = j_response['includes']['tweets']\n",
    "        tweets = user_merger(tweets,users)\n",
    "\n",
    "        tweets = rt_merger(tweets,extended)\n",
    "        tweets = rt_user_merger(tweets,users)\n",
    "\n",
    "        tweets = [assemble_tweet(tweet) for tweet in tweets]\n",
    "        \n",
    "        print(tweets[1])\n",
    "        return tweets\n",
    "\n",
    "def expand_text(tweet): \n",
    "    if tweet['retweeted_status']: \n",
    "        tweet['rt_aut'] = re.findall(r'RT @(\\w+):',tweet['text'])[0]\n",
    "        \n",
    "        \n",
    "        tweet['text'] = 'RT @' + tweet['rt_aut'] +':'+tweet['retweeted_status'].replace('\\n','')\n",
    "        return tweet\n",
    "    else: \n",
    "        tweet['rt_aut'] = ''\n",
    "        tweet['text'] = tweet['text'].replace('\\n','')\n",
    "        return tweet\n",
    "    \n",
    "def save_tweets(filename, tweets): \n",
    "    tweets = [expand_text(tweet) for tweet in tweets]\n",
    "\n",
    "    for tweet in tweets: \n",
    "        csv_writer(filename, tweet)\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "def entity_tweet_network(tweet): \n",
    "        if tweet['context_annotations']: \n",
    "            edges=[]\n",
    "            annotations = tweet['context_annotations']\n",
    "            \n",
    "            unique_ids = list(set([annotation['entity']['id']  for annotation in annotations]))\n",
    "            \n",
    "            if len(unique_ids)>1:\n",
    "                processed_ids =[]\n",
    "                for unique_id in unique_ids:\n",
    "                    for annotation in annotations: \n",
    "                        if annotation['entity']['id'] == unique_id and  unique_id not in processed_ids: \n",
    "                            edge={}\n",
    "                            edge['tweet_id'] = tweet['id']\n",
    "                            edge['annot_id'] = annotation['entity']['id'] \n",
    "                            edge['annot_name'] = annotation['entity']['name']\n",
    "\n",
    "                            edges.append(edge)\n",
    "                            processed_ids.append(unique_id)\n",
    "                            \n",
    "                \n",
    "            else: \n",
    "                edge={}\n",
    "                edge['tweet_id'] = tweet['id']\n",
    "                edge['annot_id'] = annotations[0]['entity']['id'] \n",
    "                edge['annot_name'] = annotations[0]['entity']['name']\n",
    "\n",
    "                edges.append(edge)\n",
    "        \n",
    "        \n",
    "        \n",
    "            return edges\n",
    "        \n",
    "        else:\n",
    "            return []\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields_l = ['author_id','created_at','text','geo','lang','public_metrics','id','entities','context_annotations']\n",
    "fields = ','.join(fields_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "query =   'covid lang:it' \n",
    "filename=  'test.csv'\n",
    "\n",
    "bearer_token = ''\n",
    "\n",
    "query_params = {'query': query,\n",
    "                'tweet.fields':fields , \n",
    "                'user.fields': 'id,name,username,created_at,description,public_metrics,verified',\n",
    "                'expansions':'author_id,referenced_tweets.id,referenced_tweets.id.author_id',\n",
    "                'max_results':100, \n",
    "                'start_time':'2021-01-01T00:00:00Z',\n",
    "                'end_time':'2021-01-10T00:00:00Z'}\n",
    "n_results=4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "{'author_id': '2002721', 'created_at': '2021-01-09T23:59:35.000Z', 'text': 'RT @janavel7: Parlare chiaro.\\nIl Papa: “Farò il vaccino anti-Covid. C’è un negazionismo suicida”.\\nAmen', 'geo': '', 'lang': 'it', 'public_metrics': {'retweet_count': 130, 'reply_count': 0, 'like_count': 0, 'quote_count': 0, 'impression_count': 0}, 'id': '1348056858578325505', 'entities': {'mentions': [{'start': 3, 'end': 12, 'username': 'janavel7', 'id': '2204706469'}]}, 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'user_scr_name': 'dasar', 'username': 'dasar', 'retweeted_status': 'Parlare chiaro.\\nIl Papa: “Farò il vaccino anti-Covid. C’è un negazionismo suicida”.\\nAmen', 'rt_followers': 45398, 'retweet_count': 130, 'comm_count': 6, 'favorite_count': 1312, 'exp_url': 'n/a'}\n",
      "88\n",
      "1\n",
      "{'author_id': '952525316', 'created_at': '2021-01-09T23:42:08.000Z', 'text': 'RT @janavel7: Parlare chiaro.\\nIl Papa: “Farò il vaccino anti-Covid. C’è un negazionismo suicida”.\\nAmen', 'geo': '', 'lang': 'it', 'public_metrics': {'retweet_count': 130, 'reply_count': 0, 'like_count': 0, 'quote_count': 0, 'impression_count': 0}, 'id': '1348052468664573953', 'entities': {'mentions': [{'start': 3, 'end': 12, 'username': 'janavel7', 'id': '2204706469'}]}, 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '131', 'name': 'Unified Twitter Taxonomy', 'description': 'A taxonomy of user interests. '}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'user_scr_name': 'Pissed_and_Love', 'username': 'Pissed&Love #facciamorete', 'retweeted_status': 'Parlare chiaro.\\nIl Papa: “Farò il vaccino anti-Covid. C’è un negazionismo suicida”.\\nAmen', 'rt_followers': 45398, 'retweet_count': 130, 'comm_count': 6, 'favorite_count': 1312, 'exp_url': 'n/a'}\n",
      "80\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_60924/2500683788.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#data_out=[]\n",
    "\n",
    "\n",
    "pages = int(n_results/query_params['max_results'])\n",
    "\n",
    "next_token=False\n",
    "\n",
    "for i, page in enumerate(range(pages)):\n",
    "    print(page)\n",
    "    \n",
    "    time.sleep(4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if not next_token: \n",
    "        \n",
    "        j_response = execute_req(search_url, headers=headers, params=query_params)\n",
    "       \n",
    "        tweets=process_tweets(j_response)\n",
    "        \n",
    "\n",
    "        try: \n",
    "            next_token = j_response['meta']['next_token']\n",
    "        except: \n",
    "            break\n",
    "    else:\n",
    "        updated_params = query_params\n",
    "        updated_params['next_token'] = next_token\n",
    "        j_response = execute_req(search_url, headers=headers, params=updated_params)\n",
    "        \n",
    "        tweets=process_tweets(j_response)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        try: \n",
    "            next_token = j_response['meta']['next_token']\n",
    "        except: \n",
    "            break\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    print(len(tweets))\n",
    "    \n",
    "    save_tweets(filename,tweets)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [expand_text(tweet) for tweet in tweets]\n",
    "\n",
    "for tweet in tweets: \n",
    "        csv_writer(filename, tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  extract annotations \n",
    "\n",
    "filename_annotations= 'test_entities.csv'\n",
    "all_edges=[]\n",
    "for tweet in tweets: \n",
    "    edges = entity_tweet_network(tweet)\n",
    "    all_edges.extend(edges)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author_id': '317671787',\n",
       " 'created_at': '2021-01-09T18:46:57.000Z',\n",
       " 'text': 'In Italia 19.978 nuovi casi, 483 decessi Covid, Veneto regione col numero più alto https://t.co/e2sBMSwRNe',\n",
       " 'geo': '',\n",
       " 'lang': 'it',\n",
       " 'public_metrics': {'retweet_count': 0,\n",
       "  'reply_count': 0,\n",
       "  'like_count': 0,\n",
       "  'quote_count': 0},\n",
       " 'id': '1347978182729867267',\n",
       " 'entities': {'urls': [{'start': 83,\n",
       "    'end': 106,\n",
       "    'url': 'https://t.co/e2sBMSwRNe',\n",
       "    'expanded_url': 'https://www.informazione.it/a/34CA84A0-CD71-4268-B887-27D164EE17FB/In-Italia-19-978-nuovi-casi-483-decessi-Covid-Veneto-regione-col-numero-piu-alto',\n",
       "    'display_url': 'informazione.it/a/34CA84A0-CD7…'}]},\n",
       " 'context_annotations': [{'domain': {'id': '123',\n",
       "    'name': 'Ongoing News Story',\n",
       "    'description': \"Ongoing News Stories like 'Brexit'\"},\n",
       "   'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}],\n",
       " 'user_scr_name': 'infoitinterno',\n",
       " 'username': 'informazione interno',\n",
       " 'retweeted_status': '',\n",
       " 'rt_followers': '',\n",
       " 'retweet_count': '',\n",
       " 'comm_count': '',\n",
       " 'favorite_count': '',\n",
       " 'exp_url': 'https://www.informazione.it/a/34CA84A0-CD71-4268-B887-27D164EE17FB/In-Italia-19-978-nuovi-casi-483-decessi-Covid-Veneto-regione-col-numero-piu-alto',\n",
       " 'rt_aut': ''}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
